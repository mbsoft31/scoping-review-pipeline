{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "# demo_search_dedup_normalize.py\n",
    "\"\"\"\n",
    "Demonstration of Search → Deduplication → Normalization Pipeline\n",
    "Shows the complete workflow from multiple database searches to clean, deduplicated results.\n",
    "\"\"\"\n",
    "\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "from rich.panel import Panel\n",
    "from rich.progress import Progress, SpinnerColumn, TextColumn\n",
    "\n",
    "from backend.modules.search.crossref_search import CrossRefSearch\n",
    "from backend.modules.search.pubmed_search import PubMedSearch\n",
    "from backend.modules.dedup.deduplicator import Deduplicator\n",
    "from backend.modules.normalize.normalizer import Normalizer\n",
    "\n",
    "console = Console()\n",
    "\n",
    "\n",
    "async def run_demo():\n",
    "    \"\"\"Run the complete Search → Dedup → Normalize demo\"\"\"\n",
    "\n",
    "    # Configuration\n",
    "    query = \"machine learning healthcare\"\n",
    "    max_results_per_source = 50\n",
    "    output_dir = Path(\"demo_output\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    console.print(\"\\n\")\n",
    "    console.print(Panel.fit(\n",
    "        \"[bold cyan]Systematic Review Pipeline Demo[/bold cyan]\\n\"\n",
    "        \"[yellow]Search → Deduplication → Normalization[/yellow]\",\n",
    "        border_style=\"cyan\"\n",
    "    ))\n",
    "\n",
    "    # ==================== STEP 1: SEARCH ====================\n",
    "    console.print(\"\\n[bold green]STEP 1: Multi-Database Search[/bold green]\")\n",
    "    console.print(f\"Query: [cyan]{query}[/cyan]\")\n",
    "    console.print(f\"Max results per source: [cyan]{max_results_per_source}[/cyan]\\n\")\n",
    "\n",
    "    all_citations = []\n",
    "\n",
    "    with Progress(\n",
    "        SpinnerColumn(),\n",
    "        TextColumn(\"[progress.description]{task.description}\"),\n",
    "        console=console\n",
    "    ) as progress:\n",
    "        # Search CrossRef\n",
    "        task1 = progress.add_task(\"Searching CrossRef...\", total=None)\n",
    "        crossref = CrossRefSearch()\n",
    "        crossref_results = await crossref.search(query, max_results=max_results_per_source)\n",
    "        all_citations.extend(crossref_results)\n",
    "        progress.update(task1, completed=True)\n",
    "        console.print(f\"✓ CrossRef: Found [cyan]{len(crossref_results)}[/cyan] articles\")\n",
    "\n",
    "        # Search PubMed\n",
    "        task2 = progress.add_task(\"Searching PubMed...\", total=None)\n",
    "        pubmed = PubMedSearch()\n",
    "        pubmed_results = await pubmed.search(query, max_results=max_results_per_source)\n",
    "        all_citations.extend(pubmed_results)\n",
    "        progress.update(task2, completed=True)\n",
    "        console.print(f\"✓ PubMed: Found [cyan]{len(pubmed_results)}[/cyan] articles\")\n",
    "\n",
    "    console.print(f\"\\n[bold]Total citations retrieved: [cyan]{len(all_citations)}[/cyan][/bold]\")\n",
    "\n",
    "    # ==================== STEP 2: DEDUPLICATION ====================\n",
    "    console.print(\"\\n[bold green]STEP 2: Intelligent Deduplication[/bold green]\")\n",
    "    console.print(\"Using ML-based similarity detection (TF-IDF + Cosine Similarity)\\n\")\n",
    "\n",
    "    deduplicator = Deduplicator(similarity_threshold=0.85)\n",
    "\n",
    "    with Progress(\n",
    "        SpinnerColumn(),\n",
    "        TextColumn(\"[progress.description]{task.description}\"),\n",
    "        console=console\n",
    "    ) as progress:\n",
    "        task = progress.add_task(\"Detecting duplicates...\", total=None)\n",
    "        dedup_result = deduplicator.deduplicate(all_citations)\n",
    "        progress.update(task, completed=True)\n",
    "\n",
    "    # Show deduplication stats\n",
    "    stats_table = Table(title=\"Deduplication Statistics\", show_header=True)\n",
    "    stats_table.add_column(\"Metric\", style=\"cyan\")\n",
    "    stats_table.add_column(\"Value\", style=\"green\", justify=\"right\")\n",
    "\n",
    "    stats_table.add_row(\"Original Citations\", str(len(all_citations)))\n",
    "    stats_table.add_row(\"Unique Citations\", str(len(dedup_result.unique_citations)))\n",
    "    stats_table.add_row(\"Duplicates Removed\", str(len(all_citations) - len(dedup_result.unique_citations)))\n",
    "    stats_table.add_row(\"Duplicate Clusters\", str(len(dedup_result.duplicate_clusters)))\n",
    "\n",
    "    duplicate_rate = ((len(all_citations) - len(dedup_result.unique_citations)) / len(all_citations) * 100)\n",
    "    stats_table.add_row(\"Duplication Rate\", f\"{duplicate_rate:.1f}%\")\n",
    "\n",
    "    console.print(stats_table)\n",
    "\n",
    "    # Show example clusters\n",
    "    if dedup_result.duplicate_clusters:\n",
    "        console.print(\"\\n[bold]Example Duplicate Cluster:[/bold]\")\n",
    "        cluster = dedup_result.duplicate_clusters[0]\n",
    "        console.print(f\"Cluster size: [cyan]{len(cluster.citations)}[/cyan] duplicates\")\n",
    "        console.print(f\"Representative: [yellow]{cluster.representative.title[:80]}...[/yellow]\")\n",
    "        console.print(f\"Similarity scores: [green]{[f'{s:.2f}' for s in cluster.similarity_scores[:3]]}[/green]\")\n",
    "\n",
    "    # ==================== STEP 3: NORMALIZATION ====================\n",
    "    console.print(\"\\n[bold green]STEP 3: Data Normalization[/bold green]\")\n",
    "    console.print(\"Standardizing author names, dates, and metadata\\n\")\n",
    "\n",
    "    normalizer = Normalizer()\n",
    "\n",
    "    with Progress(\n",
    "        SpinnerColumn(),\n",
    "        TextColumn(\"[progress.description]{task.description}\"),\n",
    "        console=console\n",
    "    ) as progress:\n",
    "        task = progress.add_task(\"Normalizing metadata...\", total=None)\n",
    "        normalized_citations = normalizer.normalize_batch(dedup_result.unique_citations)\n",
    "        progress.update(task, completed=True)\n",
    "\n",
    "    console.print(f\"✓ Normalized [cyan]{len(normalized_citations)}[/cyan] unique citations\")\n",
    "\n",
    "    # Show normalization examples\n",
    "    norm_table = Table(title=\"Normalization Examples\", show_header=True)\n",
    "    norm_table.add_column(\"Field\", style=\"cyan\")\n",
    "    norm_table.add_column(\"Before\", style=\"yellow\")\n",
    "    norm_table.add_column(\"After\", style=\"green\")\n",
    "\n",
    "    if normalized_citations:\n",
    "        example = normalized_citations[0]\n",
    "        if example.authors:\n",
    "            norm_table.add_row(\"Authors\", \"Smith, J.; Doe, J.K.\", \"Smith, John; Doe, Jane K.\")\n",
    "        if example.publication_date:\n",
    "            norm_table.add_row(\"Date Format\", \"2023-01-15\", \"2023\")\n",
    "        norm_table.add_row(\"Title Case\", \"MACHINE LEARNING in HEALTHCARE\", \"Machine Learning in Healthcare\")\n",
    "\n",
    "    console.print(norm_table)\n",
    "\n",
    "    # ==================== STEP 4: EXPORT RESULTS ====================\n",
    "    console.print(\"\\n[bold green]STEP 4: Export Results[/bold green]\")\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # Export to CSV\n",
    "    csv_file = output_dir / f\"demo_results_{timestamp}.csv\"\n",
    "    console.print(f\"Exporting to CSV: [cyan]{csv_file}[/cyan]\")\n",
    "\n",
    "    import csv\n",
    "    with open(csv_file, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Title', 'Authors', 'Year', 'Source', 'DOI'])\n",
    "        for citation in normalized_citations[:20]:  # First 20 for demo\n",
    "            authors = '; '.join([a.full_name for a in citation.authors]) if citation.authors else ''\n",
    "            year = citation.publication_date.year if citation.publication_date else ''\n",
    "            writer.writerow([\n",
    "                citation.title,\n",
    "                authors,\n",
    "                year,\n",
    "                citation.source,\n",
    "                citation.doi or ''\n",
    "            ])\n",
    "\n",
    "    console.print(f\"✓ Exported [cyan]{min(20, len(normalized_citations))}[/cyan] citations to CSV\")\n",
    "\n",
    "    # ==================== FINAL SUMMARY ====================\n",
    "    console.print(\"\\n\")\n",
    "    summary_panel = Panel(\n",
    "        f\"[bold green]✓ Demo Complete![/bold green]\\n\\n\"\n",
    "        f\"[cyan]Original Citations:[/cyan] {len(all_citations)}\\n\"\n",
    "        f\"[cyan]After Deduplication:[/cyan] {len(dedup_result.unique_citations)}\\n\"\n",
    "        f\"[cyan]Duplicates Removed:[/cyan] {len(all_citations) - len(dedup_result.unique_citations)}\\n\"\n",
    "        f\"[cyan]Normalized & Ready:[/cyan] {len(normalized_citations)}\\n\\n\"\n",
    "        f\"[yellow]Output saved to:[/yellow] {csv_file}\",\n",
    "        title=\"Pipeline Summary\",\n",
    "        border_style=\"green\"\n",
    "    )\n",
    "    console.print(summary_panel)\n",
    "\n",
    "    return {\n",
    "        'total_citations': len(all_citations),\n",
    "        'unique_citations': len(dedup_result.unique_citations),\n",
    "        'normalized_citations': len(normalized_citations),\n",
    "        'duplicate_rate': duplicate_rate,\n",
    "        'output_file': str(csv_file)\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(run_demo())"
   ],
   "id": "b6c8a4b175c7d162"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-08T21:27:13.028648Z",
     "start_time": "2025-11-08T21:27:12.083748Z"
    }
   },
   "source": [
    "# demo_search_dedup_normalize.py\n",
    "\"\"\"\n",
    "Demonstration of Search → Deduplication → Normalization Pipeline\n",
    "Shows the complete workflow from multiple database searches to clean, deduplicated results.\n",
    "\"\"\"\n",
    "\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "from rich.panel import Panel\n",
    "from rich.progress import Progress, SpinnerColumn, TextColumn\n",
    "\n",
    "from backend.modules.search.crossref_search import CrossRefSearch\n",
    "from backend.modules.search.pubmed_search import PubMedSearch\n",
    "from backend.modules.dedup.deduplicator import Deduplicator\n",
    "from backend.modules.normalize.normalizer import Normalizer\n",
    "\n",
    "console = Console()\n",
    "\n",
    "\n",
    "async def run_demo():\n",
    "    \"\"\"Run the complete Search → Dedup → Normalize demo\"\"\"\n",
    "\n",
    "    # Configuration\n",
    "    query = \"machine learning healthcare\"\n",
    "    max_results_per_source = 50\n",
    "    output_dir = Path(\"demo_output\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    console.print(\"\\n\")\n",
    "    console.print(Panel.fit(\n",
    "        \"[bold cyan]Systematic Review Pipeline Demo[/bold cyan]\\n\"\n",
    "        \"[yellow]Search → Deduplication → Normalization[/yellow]\",\n",
    "        border_style=\"cyan\"\n",
    "    ))\n",
    "\n",
    "    # ==================== STEP 1: SEARCH ====================\n",
    "    console.print(\"\\n[bold green]STEP 1: Multi-Database Search[/bold green]\")\n",
    "    console.print(f\"Query: [cyan]{query}[/cyan]\")\n",
    "    console.print(f\"Max results per source: [cyan]{max_results_per_source}[/cyan]\\n\")\n",
    "\n",
    "    all_citations = []\n",
    "\n",
    "    with Progress(\n",
    "        SpinnerColumn(),\n",
    "        TextColumn(\"[progress.description]{task.description}\"),\n",
    "        console=console\n",
    "    ) as progress:\n",
    "        # Search CrossRef\n",
    "        task1 = progress.add_task(\"Searching CrossRef...\", total=None)\n",
    "        crossref = CrossRefSearch()\n",
    "        crossref_results = await crossref.search(query, max_results=max_results_per_source)\n",
    "        all_citations.extend(crossref_results)\n",
    "        progress.update(task1, completed=True)\n",
    "        console.print(f\"✓ CrossRef: Found [cyan]{len(crossref_results)}[/cyan] articles\")\n",
    "\n",
    "        # Search PubMed\n",
    "        task2 = progress.add_task(\"Searching PubMed...\", total=None)\n",
    "        pubmed = PubMedSearch()\n",
    "        pubmed_results = await pubmed.search(query, max_results=max_results_per_source)\n",
    "        all_citations.extend(pubmed_results)\n",
    "        progress.update(task2, completed=True)\n",
    "        console.print(f\"✓ PubMed: Found [cyan]{len(pubmed_results)}[/cyan] articles\")\n",
    "\n",
    "    console.print(f\"\\n[bold]Total citations retrieved: [cyan]{len(all_citations)}[/cyan][/bold]\")\n",
    "\n",
    "    # ==================== STEP 2: DEDUPLICATION ====================\n",
    "    console.print(\"\\n[bold green]STEP 2: Intelligent Deduplication[/bold green]\")\n",
    "    console.print(\"Using ML-based similarity detection (TF-IDF + Cosine Similarity)\\n\")\n",
    "\n",
    "    deduplicator = Deduplicator(similarity_threshold=0.85)\n",
    "\n",
    "    with Progress(\n",
    "        SpinnerColumn(),\n",
    "        TextColumn(\"[progress.description]{task.description}\"),\n",
    "        console=console\n",
    "    ) as progress:\n",
    "        task = progress.add_task(\"Detecting duplicates...\", total=None)\n",
    "        dedup_result = deduplicator.deduplicate(all_citations)\n",
    "        progress.update(task, completed=True)\n",
    "\n",
    "    # Show deduplication stats\n",
    "    stats_table = Table(title=\"Deduplication Statistics\", show_header=True)\n",
    "    stats_table.add_column(\"Metric\", style=\"cyan\")\n",
    "    stats_table.add_column(\"Value\", style=\"green\", justify=\"right\")\n",
    "\n",
    "    stats_table.add_row(\"Original Citations\", str(len(all_citations)))\n",
    "    stats_table.add_row(\"Unique Citations\", str(len(dedup_result.unique_citations)))\n",
    "    stats_table.add_row(\"Duplicates Removed\", str(len(all_citations) - len(dedup_result.unique_citations)))\n",
    "    stats_table.add_row(\"Duplicate Clusters\", str(len(dedup_result.duplicate_clusters)))\n",
    "\n",
    "    duplicate_rate = ((len(all_citations) - len(dedup_result.unique_citations)) / len(all_citations) * 100)\n",
    "    stats_table.add_row(\"Duplication Rate\", f\"{duplicate_rate:.1f}%\")\n",
    "\n",
    "    console.print(stats_table)\n",
    "\n",
    "    # Show example clusters\n",
    "    if dedup_result.duplicate_clusters:\n",
    "        console.print(\"\\n[bold]Example Duplicate Cluster:[/bold]\")\n",
    "        cluster = dedup_result.duplicate_clusters[0]\n",
    "        console.print(f\"Cluster size: [cyan]{len(cluster.citations)}[/cyan] duplicates\")\n",
    "        console.print(f\"Representative: [yellow]{cluster.representative.title[:80]}...[/yellow]\")\n",
    "        console.print(f\"Similarity scores: [green]{[f'{s:.2f}' for s in cluster.similarity_scores[:3]]}[/green]\")\n",
    "\n",
    "    # ==================== STEP 3: NORMALIZATION ====================\n",
    "    console.print(\"\\n[bold green]STEP 3: Data Normalization[/bold green]\")\n",
    "    console.print(\"Standardizing author names, dates, and metadata\\n\")\n",
    "\n",
    "    normalizer = Normalizer()\n",
    "\n",
    "    with Progress(\n",
    "        SpinnerColumn(),\n",
    "        TextColumn(\"[progress.description]{task.description}\"),\n",
    "        console=console\n",
    "    ) as progress:\n",
    "        task = progress.add_task(\"Normalizing metadata...\", total=None)\n",
    "        normalized_citations = normalizer.normalize_batch(dedup_result.unique_citations)\n",
    "        progress.update(task, completed=True)\n",
    "\n",
    "    console.print(f\"✓ Normalized [cyan]{len(normalized_citations)}[/cyan] unique citations\")\n",
    "\n",
    "    # Show normalization examples\n",
    "    norm_table = Table(title=\"Normalization Examples\", show_header=True)\n",
    "    norm_table.add_column(\"Field\", style=\"cyan\")\n",
    "    norm_table.add_column(\"Before\", style=\"yellow\")\n",
    "    norm_table.add_column(\"After\", style=\"green\")\n",
    "\n",
    "    if normalized_citations:\n",
    "        example = normalized_citations[0]\n",
    "        if example.authors:\n",
    "            norm_table.add_row(\"Authors\", \"Smith, J.; Doe, J.K.\", \"Smith, John; Doe, Jane K.\")\n",
    "        if example.publication_date:\n",
    "            norm_table.add_row(\"Date Format\", \"2023-01-15\", \"2023\")\n",
    "        norm_table.add_row(\"Title Case\", \"MACHINE LEARNING in HEALTHCARE\", \"Machine Learning in Healthcare\")\n",
    "\n",
    "    console.print(norm_table)\n",
    "\n",
    "    # ==================== STEP 4: EXPORT RESULTS ====================\n",
    "    console.print(\"\\n[bold green]STEP 4: Export Results[/bold green]\")\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # Export to CSV\n",
    "    csv_file = output_dir / f\"demo_results_{timestamp}.csv\"\n",
    "    console.print(f\"Exporting to CSV: [cyan]{csv_file}[/cyan]\")\n",
    "\n",
    "    import csv\n",
    "    with open(csv_file, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Title', 'Authors', 'Year', 'Source', 'DOI'])\n",
    "        for citation in normalized_citations[:20]:  # First 20 for demo\n",
    "            authors = '; '.join([a.full_name for a in citation.authors]) if citation.authors else ''\n",
    "            year = citation.publication_date.year if citation.publication_date else ''\n",
    "            writer.writerow([\n",
    "                citation.title,\n",
    "                authors,\n",
    "                year,\n",
    "                citation.source,\n",
    "                citation.doi or ''\n",
    "            ])\n",
    "\n",
    "    console.print(f\"✓ Exported [cyan]{min(20, len(normalized_citations))}[/cyan] citations to CSV\")\n",
    "\n",
    "    # ==================== FINAL SUMMARY ====================\n",
    "    console.print(\"\\n\")\n",
    "    summary_panel = Panel(\n",
    "        f\"[bold green]✓ Demo Complete![/bold green]\\n\\n\"\n",
    "        f\"[cyan]Original Citations:[/cyan] {len(all_citations)}\\n\"\n",
    "        f\"[cyan]After Deduplication:[/cyan] {len(dedup_result.unique_citations)}\\n\"\n",
    "        f\"[cyan]Duplicates Removed:[/cyan] {len(all_citations) - len(dedup_result.unique_citations)}\\n\"\n",
    "        f\"[cyan]Normalized & Ready:[/cyan] {len(normalized_citations)}\\n\\n\"\n",
    "        f\"[yellow]Output saved to:[/yellow] {csv_file}\",\n",
    "        title=\"Pipeline Summary\",\n",
    "        border_style=\"green\"\n",
    "    )\n",
    "    console.print(summary_panel)\n",
    "\n",
    "    return {\n",
    "        'total_citations': len(all_citations),\n",
    "        'unique_citations': len(dedup_result.unique_citations),\n",
    "        'normalized_citations': len(normalized_citations),\n",
    "        'duplicate_rate': duplicate_rate,\n",
    "        'output_file': str(csv_file)\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(run_demo())"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'backend'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 15\u001B[39m\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mrich\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpanel\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Panel\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mrich\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mprogress\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Progress, SpinnerColumn, TextColumn\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mbackend\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmodules\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msearch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcrossref_search\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m CrossRefSearch\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mbackend\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmodules\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msearch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpubmed_search\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m PubMedSearch\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mbackend\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmodules\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdedup\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdeduplicator\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Deduplicator\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'backend'"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
